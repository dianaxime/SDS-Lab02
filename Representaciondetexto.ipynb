{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6874f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f678e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d32976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['The sky is blue and beautiful.',\n",
    "          'Love this blue and beautiful sky!',\n",
    "          'The quick brown fox jumps over the lazy dog.',\n",
    "          \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
    "          'I love green eggs, ham, sausages and bacon!',\n",
    "          'The brown fox is quick and the blue dog is lazy!',\n",
    "          'The sky is very blue and the sky is very beautiful today',\n",
    "          'The dog is lazy but the brown fox is quick!'    \n",
    "]\n",
    "etiquetas = ['weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather', 'animals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcab14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = np.array(corpus)\n",
    "corpus_df = pd.DataFrame({'Documento': corpus, 'Categoria':etiquetas})\n",
    "corpus_df = corpus_df[['Documento', 'Categoria']]\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8762645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ca2d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "norm_corpus = normalize_corpus(corpus)\n",
    "norm_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf0d3f1",
   "metadata": {},
   "source": [
    "Modelo Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c95377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "cv_matrix = cv.fit_transform(norm_corpus)\n",
    "cv_matrix = cv_matrix.toarray()\n",
    "cv_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232a2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palabras Ãºnicas del corpus\n",
    "vocabulario = cv.get_feature_names()\n",
    "# Mostrar el vector\n",
    "pd.DataFrame(cv_matrix, columns=vocabulario)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849b2ca",
   "metadata": {},
   "source": [
    "Modelo Bag of N - grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17476da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bv = CountVectorizer(ngram_range=(2,2))\n",
    "bv_matrix = bv.fit_transform(norm_corpus)\n",
    "\n",
    "bv_matrix = bv_matrix.toarray()\n",
    "vocabulario = bv.get_feature_names()\n",
    "pd.DataFrame(bv_matrix, columns=vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee66d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
    "tv_matrix = tv.fit_transform(norm_corpus)\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "vocabulario = tv.get_feature_names()\n",
    "pd.DataFrame(np.round(tv_matrix, 2), columns=vocabulario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c09d63",
   "metadata": {},
   "source": [
    "Document Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0983a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(tv_matrix)\n",
    "similarity_df = pd.DataFrame(similarity_matrix)\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1052ff2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
